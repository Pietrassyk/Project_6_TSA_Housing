{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6 Times Series Analysis (TSA) of Housing Market "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Look on the Sotred DataFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All .CSVs in the `Data` will be selected and processed to be in a pandas DataFrame with DateTimeIndex suitable for TSA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "path = \"Data/NYC/\"\n",
    "#get all cvs\n",
    "csvs = list(filter(lambda x: \".csv\" in x , listdir(path)))\n",
    "\n",
    "#convert them into DFs and store them with their names\n",
    "dfs = dict(zip(csvs,[pd.read_csv(path+name) for name in csvs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs.keys():\n",
    "    print(dfs[df].head(5))\n",
    "    print(dfs[df].tail(5))\n",
    "    print(\"------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"NYNGSP\" data is annual whereas \"NYXRCSA\" and \"NEWY636URN\" are on a monthly basis.\n",
    "\n",
    "In order to join the Data the dates have to be set to a common scale and date range. The bottle neck here is the GDP Data. It will be inflated to monthly data and then the Range from 1997 onwards is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data and rename it for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import preprocess\n",
    "preprocessed = [preprocess(dfs[df]) for df in dfs.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = pd.concat(preprocessed,axis = 1)[\"1997\":\"2017\"]\n",
    "nyc.columns = [\"GDP\", \"PriceIndex\" , \"Unemployment\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is visually inspected to determine trends,  seasonality and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nyc.plot(subplots = True, figsize=(16,10), legend = True, title = \"New York Data from 1997 untill 2018\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows:\n",
    "\n",
    "|Name|Trend|Seasonality|\n",
    "|:----|-----|-----------|\n",
    "|GDP|upwards|none|\n",
    "|Prices|upwards|none|\n",
    "|Unemployment|steady|yearly|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the previous section, there are Trends and Seasonality that have to be dealt with.\n",
    "In order to remove trends and seasonality, the data needs to be transformed further. The goal is to make each series stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dickey-Fuller-Test is used to determine how stationary a series is. The critical value here is the p-value. If it is less than the confidence level of 0.05 we consider the series to be stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import eval_stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#original Value for the GDP column:\n",
    "nyc[\"GDP\"].plot(figsize=(16,4));\n",
    "eval_stationary(nyc[\"GDP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#applying rolling mean\n",
    "window = 2\n",
    "new_name = \"GDP\"+\"_roll_\"+ str(window)\n",
    "nyc[new_name] = nyc[\"GDP\"] - nyc[\"GDP\"].rolling(window = window).mean()\n",
    "eval_stationary(nyc[new_name])\n",
    "\n",
    "#plot result\n",
    "nyc[new_name].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casey Shiller Index (CSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc[\"PriceIndex\"].plot(figsize=(16,4));\n",
    "plt.show()\n",
    "eval_stationary(nyc[\"PriceIndex\"])\n",
    "\n",
    "#applying rolling mean\n",
    "window = 2\n",
    "new_name = \"PriceIndex\"+\"_roll_\"+ str(window)\n",
    "nyc[new_name] = nyc[\"PriceIndex\"] - nyc[\"PriceIndex\"].rolling(window = window).mean()\n",
    "\n",
    "#plot result\n",
    "nyc[new_name].plot(figsize=(16,4));\n",
    "eval_stationary(nyc[new_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nyc[\"Unemployment\"].plot(figsize=(16,4));\n",
    "plt.show()\n",
    "eval_stationary(nyc[\"Unemployment\"])\n",
    "\n",
    "#applying rolling mean\n",
    "window = 3\n",
    "new_name = \"Unemployment\"+\"_roll_\"+ str(window)\n",
    "nyc[new_name] = nyc[\"Unemployment\"] - nyc[\"Unemployment\"].rolling(window = window).mean()\n",
    "\n",
    "#plot result\n",
    "nyc[new_name].plot(figsize=(16,4));\n",
    "eval_stationary(nyc[new_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform a 80/20 train test split\n",
    "import math\n",
    "split = math.floor(len(nyc)*0.8)\n",
    "end = len(nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"PriceIndex\"\n",
    "X_train = nyc.copy().dropna().iloc[:split]\n",
    "X_test = nyc.copy().dropna().iloc[split:]\n",
    "y_train = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "#X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "#X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nyc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = X_train[['GDP_roll_2',\n",
    "               'PriceIndex_roll_2',\n",
    "               'Unemployment_roll_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.plot(subplots = False, figsize=(16,10), title = \"Stationary Features\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in plot_df.columns:\n",
    "    plt.figure( figsize = (16,6))\n",
    "    plt.title(f\"Autocorrelation of {col}\")\n",
    "    pd.plotting.autocorrelation_plot(plot_df[col]);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "\n",
    "for col in plot_df.columns:\n",
    "    print(col)\n",
    "    plot_acf(plot_df[col],lags=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in plot_df.columns:\n",
    "    print(col)\n",
    "    plot_pacf(plot_df[col],lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For forecasting the future CSI movement the following models will be tested:\n",
    "+ ARIMA\n",
    "+ SARIMA\n",
    "+ multivariant ARIMA\n",
    "\n",
    "After each test model performance is evaluated by ________ and ultimately a final model is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = X_train.copy()\n",
    "fore_cast_span = end-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`order = (p , d, q)`\n",
    "+ p = #autoregressive degrees --> auto regression plot (where most extreme)\n",
    "+ d = nonseasonal differences --> amount of differences\n",
    "+ q = lagged forecast errors --> amount if difference where the error is compute`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "mod = sm.tsa.ARIMA(model_df[target],order=(2,1,0), dates=model_df.index)\n",
    "res = mod.fit()\n",
    "\n",
    "#predict\n",
    "forecast = pd.concat([X_train,X_test], axis = 0)\n",
    "forecast['forecast'] = res.predict(start = split, end= end, dynamic=True, typ='levels')  \n",
    "\n",
    "#evaluate\n",
    "y_pred = forecast.dropna()[\"forecast\"]\n",
    "y_true = forecast.dropna()[target]\n",
    "RMSE = round(np.sqrt(metrics.mean_squared_error(y_pred, y_true))/y_true.std(),3)\n",
    "\n",
    "#plot\n",
    "forecast[[target, 'forecast']].plot(figsize=(8, 6))\n",
    "print(f\"RMSE for Model-Forecast : {RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA with Exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define exog\n",
    "exogs = [\"Unemployment\"]\n",
    "if exogs:\n",
    "    exog = X_train[exogs]\n",
    "\n",
    "#fit the model\n",
    "mod = sm.tsa.ARIMA(model_df[target],order=(2,1,0), dates=model_df.index, exog=exog)\n",
    "res = mod.fit()\n",
    "\n",
    "#predict\n",
    "forecast = pd.concat([X_train,X_test], axis = 0)\n",
    "forecast['forecast'] = res.predict(start = split, end= end, dynamic=True, typ='levels', exog=exog)  \n",
    "\n",
    "#evaluate\n",
    "y_pred = forecast.dropna()[\"forecast\"]\n",
    "y_true = forecast.dropna()[target]\n",
    "RMSE = round(np.sqrt(metrics.mean_squared_error(y_pred, y_true))/y_true.std(),3)\n",
    "\n",
    "#plot\n",
    "forecast[[target, 'forecast']].plot(figsize=(8, 6))\n",
    "print(f\"RMSE for Model-Forecast : {RMSE} standard derivations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(range(1,3))\n",
    "d = list(range(0,3))\n",
    "q = list(range(4))\n",
    "\n",
    "pdq = list(it.product(p,d,q))\n",
    "PDQ = list(it.product(p,d,q,[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "i= 0\n",
    "for arima in pdq:\n",
    "    for S in PDQ:\n",
    "        print(f\"Fit {i}/{len(pdq)*len(PDQ)}\", end = \"\\r\")\n",
    "        try:\n",
    "            model = sm.tsa.SARIMAX(X_train[target], \n",
    "                               order = arima , \n",
    "                               seasonal_order=S, \n",
    "                               enforce_stationarity= False, \n",
    "                               enforce_invertibility=False)\n",
    "            output = model.fit()\n",
    "            res = output.aic\n",
    "        except:\n",
    "            res = \"Error\"\n",
    "        i+=1\n",
    "        out.append({\"order\": arima,\n",
    "                   \"seasonal_order\" : S,\n",
    "                   \"AIC\": res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.SARIMAX(model_df[target], dates = model_df.index, enforce_stationarity= False)\n",
    "res = model.fit()\n",
    "res.aic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
